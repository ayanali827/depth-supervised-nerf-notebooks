{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# 05 - Hard Depth-Guided Sampling\n", "\n", "Training NeRF with depth-guided sampling strategy."]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Hard Depth Rendering"]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": ["import torch\n", "import torch.nn.functional as F\n", "\n", "def render_rays_hard(model, rays_o, rays_d, near, far, N_samples,\n", "                     depth_gt=None, depth_mask=None, eps=0.5,\n", "                     white_bg=True, return_extras=False):\n", "    \n", "    N_rays = rays_o.shape[0]\n", "    \n", "    # === DEPTH-GUIDED SAMPLING ===\n", "    if depth_gt is not None and depth_mask is not None and depth_mask.any():\n", "        # HARD strategy: 75% samples near depth, 25% uniform\n", "        N_guided = int(N_samples * 0.75)\n", "        N_uniform = N_samples - N_guided\n", "        \n", "        # 1) Uniform samples\n", "        t_uniform = torch.linspace(near, far, N_uniform, device=rays_o.device)\n", "        t_uniform = t_uniform[None, :].expand(N_rays, -1)\n", "        \n", "        # 2) Depth-guided samples\n", "        t_guided = []\n", "        for i in range(N_rays):\n", "            if depth_mask[i] > 0.5:\n", "                depth_center = depth_gt[i].item()\n", "                depth_min = max(near, depth_center - eps/2)\n", "                depth_max = min(far, depth_center + eps/2)\n", "                t_ray = torch.linspace(depth_min, depth_max, N_guided, device=rays_o.device)\n", "            else:\n", "                t_ray = torch.linspace(near, far, N_guided, device=rays_o.device)\n", "            t_guided.append(t_ray)\n", "        \n", "        t_guided = torch.stack(t_guided, dim=0)\n", "        z_vals = torch.cat([t_uniform, t_guided], dim=1)\n", "        z_vals, _ = torch.sort(z_vals, dim=1)\n", "    else:\n", "        z_vals = torch.linspace(near, far, N_samples, device=rays_o.device)\n", "        z_vals = z_vals[None, :].expand(N_rays, -1)\n", "    \n", "    # === VOLUME RENDERING ===\n", "    pts = rays_o[:, None, :] + rays_d[:, None, :] * z_vals[..., None]\n", "    \n", "    dirs = F.normalize(rays_d, dim=-1)\n", "    dirs_enc = pe_dir(dirs)\n", "    pts_enc = pe_xyz(pts)\n", "    \n", "    N, S = pts_enc.shape[:2]\n", "    x = pts_enc.reshape(N * S, -1)\n", "    d = dirs_enc[:, None, :].expand(N, S, -1).reshape(N * S, -1)\n", "    \n", "    rgb, sigma = model(x, d)\n", "    rgb = rgb.view(N, S, 3)\n", "    sigma = sigma.view(N, S)\n", "    \n", "    deltas = z_vals[:, 1:] - z_vals[:, :-1]\n", "    deltas = torch.cat([deltas, 1e-3 * torch.ones_like(deltas[:, :1])], dim=-1)\n", "    alpha = 1.0 - torch.exp(-sigma * deltas)\n", "    trans = torch.cumprod(\n", "        torch.cat([torch.ones_like(alpha[:, :1]), 1. - alpha + 1e-10], dim=-1),\n", "        dim=-1\n", "    )[:, :-1]\n", "    weights = alpha * trans\n", "    \n", "    rgb_map = (weights[..., None] * rgb).sum(dim=1)\n", "    if white_bg:\n", "        rgb_map = rgb_map + (1 - weights.sum(dim=1, keepdim=True))\n", "    \n", "    depth_pred = (weights * z_vals).sum(dim=1)\n", "    \n", "    if return_extras:\n", "        return rgb_map, depth_pred, weights, z_vals, sigma\n", "    else:\n", "        return rgb_map, depth_pred"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Loss Functions"]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": ["def free_space_loss(sigma, z_vals, depth_gt, depth_mask):\n", "    if z_vals.shape[0] == 1:\n", "        z_vals = z_vals.expand(sigma.shape[0], -1)\n", "    \n", "    before_surface = z_vals < depth_gt.unsqueeze(-1)\n", "    valid = depth_mask.unsqueeze(-1) > 0.5\n", "    mask = before_surface & valid\n", "    \n", "    if mask.sum() == 0:\n", "        return torch.tensor(0.0, device=sigma.device)\n", "    \n", "    loss = (sigma * mask.float()).sum() / (mask.float().sum() + 1e-6)\n", "    return loss\n", "\n", "def surface_concentration_loss(weights, z_vals, depth_gt, depth_mask):\n", "    if z_vals.shape[0] == 1:\n", "        z_vals = z_vals.expand(weights.shape[0], -1)\n", "    \n", "    depth_pred = (weights * z_vals).sum(dim=1)\n", "    depth_l1 = (depth_pred[depth_mask] - depth_gt[depth_mask]).abs().mean()\n", "    \n", "    depth_sq = (weights * z_vals ** 2).sum(dim=1)\n", "    variance = (depth_sq - depth_pred ** 2).clamp(min=0.0)\n", "    variance_loss = variance[depth_mask].mean()\n", "    \n", "    return depth_l1 + 0.1 * variance_loss"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Training Loop"]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": ["import os\n", "import numpy as np\n", "import torch\n", "from tqdm.auto import tqdm\n", "from pathlib import Path\n", "\n", "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n", "\n", "def to_tensor(x):\n", "    if x is None:\n", "        return None\n", "    return torch.from_numpy(x).to(device)\n", "\n", "images = to_tensor(imgs_train).float()\n", "poses = to_tensor(poses_train).float()\n", "depths = to_tensor(depths_train).float() if depths_train is not None else None\n", "\n", "N_imgs, Ht, Wt = images.shape[:3]\n", "\n", "psnr_history = []\n", "loss_history = []\n", "\n", "iters = 20000\n", "batch_rays = 1024\n", "lr = 5e-4\n", "N_samples = 64\n", "\n", "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n", "\n", "def psnr(mse):\n", "    return -10.0 * torch.log10(mse)\n", "\n", "print('Starting hard depth training...')\n", "pbar = tqdm(range(iters))\n", "\n", "for it in pbar:\n", "    i = torch.randint(0, N_imgs, (1,)).item()\n", "    c2w = poses[i]\n", "    rays_o, rays_d = get_rays(Ht, Wt, focal, c2w)\n", "    target = images[i].view(-1, 3)\n", "    \n", "    idx = torch.randint(0, target.shape[0], (batch_rays,), device=device)\n", "    rays_o_b = rays_o.view(-1, 3)[idx]\n", "    rays_d_b = rays_d.view(-1, 3)[idx]\n", "    target_b = target[idx]\n", "    \n", "    # Prepare depth\n", "    if depths is not None:\n", "        depth_gt_full = depths[i]\n", "        depth_gt_b = depth_gt_full.view(-1)[idx]\n", "        near, far = 2.0, 6.0\n", "        depth_valid = (depth_gt_full > near) & (depth_gt_full < far)\n", "        depth_mask_b = depth_valid.view(-1)[idx]\n", "    else:\n", "        depth_gt_b = None\n", "        depth_mask_b = None\n", "    \n", "    # Render with hard sampling\n", "    rgb_pred, depth_pred, weights, z_vals, sigma = render_rays_hard(\n", "        model, rays_o_b, rays_d_b,\n", "        near=2.0, far=6.0, N_samples=N_samples,\n", "        depth_gt=depth_gt_b, depth_mask=depth_mask_b,\n", "        eps=0.3, return_extras=True\n", "    )\n", "    \n", "    # Losses\n", "    rgb_loss = F.mse_loss(rgb_pred, target_b)\n", "    \n", "    if depths is not None:\n", "        freespace = free_space_loss(sigma, z_vals, depth_gt_b, depth_mask_b)\n", "        surface = surface_concentration_loss(weights, z_vals, depth_gt_b, depth_mask_b)\n", "        depth_loss = freespace + surface\n", "        loss = rgb_loss + 0.005 * freespace + 0.005 * surface\n", "    else:\n", "        freespace = torch.tensor(0.0, device=device)\n", "        surface = torch.tensor(0.0, device=device)\n", "        loss = rgb_loss\n", "    \n", "    optimizer.zero_grad()\n", "    loss.backward()\n", "    optimizer.step()\n", "    \n", "    if (it + 1) % 100 == 0:\n", "        if depths is not None:\n", "            pbar.set_description(\n", "                f'it {it+1} | RGB: {rgb_loss.item():.5f} | '
", "                f'Free: {freespace.item():.5f} | '
", "                f'Surf: {surface.item():.5f} | '
", "                f'PSNR: {psnr(rgb_loss).item():.2f} dB'\n", "            )\n", "        else:\n", "            pbar.set_description(f'it {it+1} | loss {loss.item():.5f}')\n", "\n", "# Save\n", "save_dir = Path('results/hard')\n", "save_dir.mkdir(parents=True, exist_ok=True)\n", "\n", "np.save(save_dir / 'psnr_history.npy', np.array(psnr_history))\n", "np.save(save_dir / 'loss_history.npy', np.array(loss_history))\n", "torch.save(model.state_dict(), save_dir / 'model_hard.pth')\n", "\n", "print(f'âœ… Hard depth training complete! Results saved to {save_dir}')"]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}