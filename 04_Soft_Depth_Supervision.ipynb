{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# 04 - Soft Depth Supervision\n", "\n", "Training NeRF with soft MSE depth loss."]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": ["import os\n", "import numpy as np\n", "import torch\n", "import torch.nn.functional as F\n", "from tqdm.auto import tqdm\n", "from pathlib import Path\n", "\n", "device = 'cuda' if torch.cuda.is_available() else 'cpu'"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Soft Depth Rendering Function"]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": ["def render_rays_soft(nerf, rays_o, rays_d, near, far, N_samples, white_bg=True):\n", "    # Stratified sampling\n", "    z_vals = torch.linspace(near, far, N_samples, device=rays_o.device)\n", "    z_vals = z_vals.unsqueeze(0)\n", "    \n", "    pts = rays_o[..., None, :] + rays_d[..., None, :] * z_vals[..., :, None]\n", "    pts_flat = pts.reshape(-1, 3)\n", "    dirs_flat = rays_d.unsqueeze(1).expand_as(pts).reshape(-1, 3)\n", "    \n", "    # Encode\n", "    pts_enc = pe_xyz(pts_flat)\n", "    dirs_enc = pe_dir(dirs_flat)\n", "    \n", "    # MLP forward\n", "    rgb, sigma = nerf(pts_enc, dirs_enc)\n", "    rgb = rgb.view(*pts.shape[:-1], 3)\n", "    sigma = sigma.view(*pts.shape[:-1])\n", "    \n", "    # Volume rendering\n", "    deltas = z_vals[..., 1:] - z_vals[..., :-1]\n", "    deltas = torch.cat([deltas, 1e-3 * torch.ones_like(deltas[..., :1])], dim=-1)\n", "    alpha = 1.0 - torch.exp(-sigma * deltas)\n", "    trans = torch.cumprod(\n", "        torch.cat([torch.ones_like(alpha[..., :1]), 1.-alpha + 1e-10], dim=-1),\n", "        dim=-1\n", "    )[..., :-1]\n", "    weights = alpha * trans\n", "    \n", "    rgb_map = (weights[..., None] * rgb).sum(dim=-2)\n", "    if white_bg:\n", "        rgb_map = rgb_map + (1 - weights.sum(dim=-1, keepdim=True))\n", "    \n", "    depth_soft = (weights * z_vals).sum(dim=-1)\n", "    \n", "    return rgb_map, depth_soft"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Training Loop"]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": ["def to_tensor(x):\n", "    if x is None:\n", "        return None\n", "    return torch.from_numpy(x).to(device)\n", "\n", "# Load data\n", "images = to_tensor(imgs_train).float()\n", "poses = to_tensor(poses_train).float()\n", "depths = to_tensor(depths_train).float() if depths_train is not None else None\n", "\n", "N_imgs, Ht, Wt = images.shape[:3]\n", "psnr_history = []\n", "loss_history = []\n", "\n", "# Training parameters\n", "iters = 20000\n", "batch_rays = 1024\n", "lr = 5e-4\n", "lambda_depth = 0.01 if depths is not None else 0.0\n", "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n", "\n", "def psnr(mse):\n", "    return -10.0 * torch.log10(mse)\n", "\n", "print('Starting soft depth training...')\n", "pbar = tqdm(range(iters))\n", "\n", "for it in pbar:\n", "    i = torch.randint(0, N_imgs, (1,)).item()\n", "    c2w = poses[i]\n", "    rays_o, rays_d = get_rays(Ht, Wt, focal, c2w)\n", "    target = images[i].view(-1, 3)\n", "    \n", "    idx = torch.randint(0, target.shape[0], (batch_rays,), device=device)\n", "    rays_o_b = rays_o.view(-1, 3)[idx]\n", "    rays_d_b = rays_d.view(-1, 3)[idx]\n", "    target_b = target[idx]\n", "    \n", "    rgb, depth_pred = render_rays_soft(model, rays_o_b, rays_d_b, near=2.0, far=6.0, N_samples=64)\n", "    \n", "    rgb_loss = F.mse_loss(rgb, target_b)\n", "    depth_loss = torch.tensor(0.0, device=device)\n", "    \n", "    if depths is not None:\n", "        depth_gt_full = depths[i]\n", "        depth_gt_b = depth_gt_full.view(-1)[idx]\n", "        depth_loss = ((depth_pred - depth_gt_b)**2).mean()\n", "    \n", "    loss = rgb_loss + lambda_depth * depth_loss\n", "    loss_history.append(loss.item())\n", "    psnr_history.append(psnr(rgb_loss).item())\n", "    \n", "    optimizer.zero_grad()\n", "    loss.backward()\n", "    optimizer.step()\n", "    \n", "    if (it + 1) % 100 == 0:\n", "        if depths is not None:\n", "            msg = f\"it {it+1} | RGB: {rgb_loss.item():.5f} | Depth: {depth_loss.item():.5f} | Total: {loss.item():.5f} | PSNR: {psnr(rgb_loss).item():.2f} dB\"\n", "            pbar.set_description(msg)\n", "        else:\n", "            pbar.set_description(f'it {it+1} | loss {loss.item():.5f} | psnr {psnr(rgb_loss).item():.2f} dB')\n", "\n", "# Save results\n", "save_dir = Path('results/soft')\n", "save_dir.mkdir(parents=True, exist_ok=True)\n", "np.save(save_dir / 'psnr_history.npy', np.array(psnr_history))\n", "np.save(save_dir / 'loss_history.npy', np.array(loss_history))\n", "torch.save(model.state_dict(), save_dir / 'model_soft.pth')\n", "print(f'Soft depth training complete! Results saved to {save_dir}')"]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}