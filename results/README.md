# Results Directory

This directory contains all experimental outputs: trained models, evaluation metrics, and rendered visualizations.

---

## ğŸš¨ **Important: Results are NOT Included in Repository**

The results are **NOT stored in Git** because:
- Model weights (.pth files): ~5 MB each Ã— 4 = 20 MB
- Rendered videos (.mp4 files): ~100 MB each Ã— 5 = 500 MB
- Total size: ~600 MB (exceeds GitHub limits)

**Results are hosted on Google Drive** (links in main README.md)

---

## ğŸ“ **Directory Structure**

After running all experiments, this folder will contain:

```
results/
â”œâ”€â”€ README.md                           â† This file
â”‚
â”œâ”€â”€ baseline/                           â† Experiment 1: RGB loss only
â”‚   â”œâ”€â”€ model_baseline.pth             (~5 MB) Trained NeRF weights
â”‚   â”œâ”€â”€ psnr_history.npy               Training PSNR over iterations
â”‚   â”œâ”€â”€ loss_history.npy               Training loss over iterations
â”‚   â””â”€â”€ renders/
â”‚       â”œâ”€â”€ novel_view_000.png
â”‚       â”œâ”€â”€ novel_view_001.png
â”‚       â”œâ”€â”€ ...
â”‚       â”œâ”€â”€ novel_view_119.png
â”‚       â”œâ”€â”€ baseline.mp4                (~100 MB) 360Â° rotation video
â”‚       â””â”€â”€ baseline.gif                (~20 MB) GIF animation
â”‚
â”œâ”€â”€ soft/                               â† Experiment 2: + Soft depth loss
â”‚   â”œâ”€â”€ model_soft.pth
â”‚   â”œâ”€â”€ psnr_history.npy
â”‚   â”œâ”€â”€ loss_history.npy
â”‚   â””â”€â”€ renders/
â”‚       â”œâ”€â”€ soft.mp4
â”‚       â””â”€â”€ soft.gif
â”‚
â”œâ”€â”€ hard/                               â† Experiment 3: + Hard depth sampling
â”‚   â”œâ”€â”€ model_hard.pth
â”‚   â”œâ”€â”€ psnr_history.npy
â”‚   â”œâ”€â”€ loss_history.npy
â”‚   â””â”€â”€ renders/
â”‚       â”œâ”€â”€ hard.mp4
â”‚       â””â”€â”€ hard.gif
â”‚
â”œâ”€â”€ hybrid/                             â† Experiment 4: Combined approach
â”‚   â”œâ”€â”€ model_hybrid.pth
â”‚   â”œâ”€â”€ psnr_history.npy
â”‚   â”œâ”€â”€ loss_history.npy
â”‚   â””â”€â”€ renders/
â”‚       â”œâ”€â”€ hybrid.mp4
â”‚       â””â”€â”€ hybrid.gif
â”‚
â”œâ”€â”€ evaluation_results.npy              â† Comprehensive metrics (all strategies)
â”œâ”€â”€ comparison_plot.png                 â† Side-by-side visual comparison
â”œâ”€â”€ psnr_curves.png                     â† Training PSNR over time
â”œâ”€â”€ comparison.mp4                      (~200 MB) All 4 strategies side-by-side
â”‚
â””â”€â”€ depth_error_maps/                   â† Depth accuracy visualizations
    â”œâ”€â”€ baseline_depth_error.png
    â”œâ”€â”€ soft_depth_error.png
    â”œâ”€â”€ hard_depth_error.png
    â””â”€â”€ hybrid_depth_error.png
```

**Total size after all experiments:** ~600 MB

---

## ğŸ¯ **How to Generate Results**

### Step 1: Run Experiments (Generate Models)

```bash
# From repository root

# Experiment 1: Baseline (12-15 hours)
jupyter notebook 03_Baseline_NeRF.ipynb
# â†’ Creates results/baseline/model_baseline.pth

# Experiment 2: Soft Depth (13-15 hours)
jupyter notebook 04_Soft_Depth_Supervision.ipynb
# â†’ Creates results/soft/model_soft.pth

# Experiment 3: Hard Depth (15-18 hours)
jupyter notebook 05_Hard_Depth_Sampling.ipynb
# â†’ Creates results/hard/model_hard.pth

# Experiment 4: Hybrid (15-18 hours)
jupyter notebook 06_Hybrid_Strategy.ipynb
# â†’ Creates results/hybrid/model_hybrid.pth
```

**Total training time:** 55-66 hours (2-3 days on single GPU)

**Tip:** Run in parallel on multiple GPUs if available

---

### Step 2: Generate Comparison Metrics

```bash
# After all 4 models are trained
jupyter notebook 07_Comprehensive_Evaluation.ipynb

# Outputs:
# - results/evaluation_results.npy
# - results/comparison_plot.png
# - results/psnr_curves.png
# - results/depth_error_maps/*.png
```

**Time:** 30-60 minutes

---

### Step 3: Render Videos

```bash
# Generate novel view videos for all strategies
jupyter notebook 08_Rendering_and_Visualization.ipynb

# Outputs:
# - results/baseline/renders/baseline.mp4
# - results/soft/renders/soft.mp4
# - results/hard/renders/hard.mp4
# - results/hybrid/renders/hybrid.mp4
# - results/comparison.mp4 (side-by-side)
```

**Time:** 1-2 hours

---

## ğŸ“¦ **Download Pre-Trained Results**

If you want to skip training and directly evaluate/visualize:

**Google Drive:** [Download All Results (~600 MB)](https://drive.google.com/drive/folders/placeholder)

After downloading:

```bash
# Extract to results/ folder
unzip results.zip
mv results_backup/* results/

# Verify
ls results/baseline/model_baseline.pth
ls results/hybrid/renders/hybrid.mp4
```

Then jump to notebooks 07 (Evaluation) or 08 (Rendering).

---

## ğŸ“Š **Expected Metrics**

After running evaluation (notebook 07), you should see:

| Strategy | PSNR â†‘ | SSIM â†‘ | LPIPS â†“ | Depth L1 â†“ |
|----------|--------|--------|---------|----------|
| Baseline | ~22.5 dB | ~0.90 | ~0.085 | N/A |
| Soft | ~22.4 dB | ~0.90 | ~0.089 | ~0.34 m |
| Hard | ~22.0 dB | ~0.90 | ~0.098 | ~0.28 m |
| Hybrid | ~22.1 dB | ~0.90 | ~0.092 | ~0.31 m |

*Your results may vary Â±1-2 dB depending on random seed and training duration*

---

## ğŸ” **Inspect Results**

### Check Model Weights

```python
import torch

# Load a trained model
checkpoint = torch.load('results/hybrid/model_hybrid.pth')
print(f"Model architecture: {checkpoint.keys()}")
```

### Plot Training Curves

```python
import numpy as np
import matplotlib.pyplot as plt

# Load training history
psnr_baseline = np.load('results/baseline/psnr_history.npy')
psnr_hybrid = np.load('results/hybrid/psnr_history.npy')

# Plot comparison
plt.plot(psnr_baseline, label='Baseline')
plt.plot(psnr_hybrid, label='Hybrid')
plt.xlabel('Iteration')
plt.ylabel('PSNR (dB)')
plt.legend()
plt.show()
```

### View Rendered Videos

```bash
# Play video (macOS)
open results/hybrid/renders/hybrid.mp4

# Play video (Linux)
vlc results/hybrid/renders/hybrid.mp4

# Play video (Windows)
start results/hybrid/renders/hybrid.mp4
```

---

## ğŸ› ï¸ **Troubleshooting**

### Problem: "FileNotFoundError: model_baseline.pth"

**Cause:** Model hasn't been trained yet

**Solution:**
```bash
# Train the model first
jupyter notebook 03_Baseline_NeRF.ipynb
```

---

### Problem: "CUDA out of memory"

**Solution:** Reduce batch size in training notebooks

```python
# In 03, 04, 05, 06 notebooks, change:
batch_rays = 512  # Instead of 1024
N_samples = 32    # Instead of 64
```

---

### Problem: Training Too Slow

**Check GPU utilization:**
```bash
watch -n 1 nvidia-smi
# GPU utilization should be 90-100%
```

**If low utilization:**
- Increase `batch_rays` (if memory allows)
- Check if CPU bottleneck (data loading)
- Ensure CUDA is properly installed

---

### Problem: Poor Results (Low PSNR)

**Possible causes:**
1. **Insufficient training** - Try 50K iterations instead of 20K
2. **Learning rate too high/low** - Default 5e-4 usually works
3. **Data not loaded correctly** - Check `01_Data_Loading.ipynb`
4. **Depth data quality** - Verify depth maps in dataset

---

## ğŸ“ **For Course Reviewers**

If you're reviewing this project and want to verify results without retraining:

1. **Download pre-trained models** from Google Drive (link in main README)

2. **Place in results/ folder:**
   ```bash
   unzip results.zip -d results/
   ```

3. **Run evaluation:**
   ```bash
   jupyter notebook 07_Comprehensive_Evaluation.ipynb
   ```

4. **View videos:**
   ```bash
   open results/comparison.mp4
   ```

**Estimated time to verify:** 15-30 minutes

---

## ğŸ”’ **Why Results are NOT in Git**

### Size Issues:
- Model weights: 20 MB total
- Videos: 500+ MB total
- GitHub limit: 100 MB per file, ~1 GB repo size

### Best Practice:
- **Code** (notebooks) â†’ Git
- **Data** (datasets) â†’ External download
- **Results** (models, videos) â†’ Cloud storage (Google Drive)
- **Small artifacts** (plots) â†’ Git (if <1 MB)

### Alternative Storage:
- **Git LFS** (Large File Storage) - Still problematic for 500+ MB
- **DVC** (Data Version Control) - Overkill for course project
- **Google Drive** - Simple and accessible âœ…

---

## ğŸ”— **Access Full Results**

**Google Drive Folder Structure:**

```
NeRF-Depth-Research-Results/
â”œâ”€â”€ trained_models/
â”‚   â”œâ”€â”€ baseline.pth (5 MB)
â”‚   â”œâ”€â”€ soft.pth (5 MB)
â”‚   â”œâ”€â”€ hard.pth (5 MB)
â”‚   â””â”€â”€ hybrid.pth (5 MB)
â”‚
â”œâ”€â”€ rendered_videos/
â”‚   â”œâ”€â”€ baseline.mp4 (100 MB)
â”‚   â”œâ”€â”€ soft.mp4 (100 MB)
â”‚   â”œâ”€â”€ hard.mp4 (100 MB)
â”‚   â”œâ”€â”€ hybrid.mp4 (100 MB)
â”‚   â””â”€â”€ comparison.mp4 (200 MB)
â”‚
â”œâ”€â”€ evaluation_plots/
â”‚   â”œâ”€â”€ psnr_comparison.png
â”‚   â”œâ”€â”€ ssim_comparison.png
â”‚   â”œâ”€â”€ training_curves.png
â”‚   â””â”€â”€ depth_error_maps.zip
â”‚
â””â”€â”€ README.txt
```

**Download Link:** [See main README.md](../README.md#research-artifacts)

---

## â„¹ï¸ **Questions?**

**Issues with results generation:**
1. Check training logs in notebooks
2. Verify GPU availability: `nvidia-smi`
3. See [GitHub Issues](https://github.com/ayanali827/depth-supervised-nerf-notebooks/issues)
4. Contact: ayansaleem827@gmail.com

**Expected timeline:**
- Training all 4 models: 2-3 days (single GPU)
- Evaluation + rendering: 2-3 hours
- Total: ~3 days from start to completion

---

**Last Updated:** December 13, 2025  
**Author:** Ayan Ali  
**Project:** Improving NeRF Training Quality Using Depth Data
