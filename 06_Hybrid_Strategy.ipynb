{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# 06 - Hybrid Strategy\n", "\n", "Combining soft MSE depth loss with hard depth-guided sampling."]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Hybrid Rendering Function"]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": ["import torch\n", "import torch.nn.functional as F\n", "\n", "def render_rays_hybrid(nerf, rays_o, rays_d, near, far, N_samples,\n", "                       depth_gt=None, depth_mask=None, eps=0.3,\n", "                       white_bg=True, return_extras=False):\n", "    \n", "    N = rays_o.shape[0]\n", "    \n", "    # Hybrid strategy: 50% depth-guided, 50% uniform\n", "    if depth_gt is not None and depth_mask is not None and depth_mask.any():\n", "        N_guided = N_samples // 2\n", "        N_uniform = N_samples - N_guided\n", "        \n", "        # Uniform samples\n", "        t_uniform = torch.linspace(near, far, N_uniform, device=rays_o.device)\n", "        t_uniform = t_uniform[None, :].expand(N, -1)\n", "        \n", "        # Depth-guided samples\n", "        z_guided = torch.zeros(N, N_guided, device=rays_o.device)\n", "        for i in range(N):\n", "            if depth_mask[i]:\n", "                depth_center = depth_gt[i].item()\n", "                near_guided = max(near, depth_center - eps/2)\n", "                far_guided = min(far, depth_center + eps/2)\n", "                t_guided = torch.linspace(0., 1., N_guided, device=rays_o.device)\n", "                z_guided[i] = near_guided * (1. - t_guided) + far_guided * t_guided\n", "            else:\n", "                t_guided = torch.linspace(0., 1., N_guided, device=rays_o.device)\n", "                z_guided[i] = near * (1. - t_guided) + far * t_guided\n", "        \n", "        z_vals = torch.cat([t_uniform, z_guided], dim=1)\n", "        z_vals, _ = torch.sort(z_vals, dim=1)\n", "    else:\n", "        t_vals = torch.linspace(0., 1., steps=N_samples, device=rays_o.device)\n", "        z_vals = near * (1. - t_vals) + far * t_vals\n", "        z_vals = z_vals[None, :].repeat(rays_o.shape[0], 1)\n", "    \n", "    # Volume rendering\n", "    pts = rays_o[:, None, :] + rays_d[:, None, :] * z_vals[..., None]\n", "    \n", "    dirs = F.normalize(rays_d, dim=-1)\n", "    dirs_enc = pe_dir(dirs)\n", "    pts_enc = pe_xyz(pts)\n", "    \n", "    N_rays, S = pts_enc.shape[:2]\n", "    x = pts_enc.reshape(N_rays * S, -1)\n", "    d = dirs_enc[:, None, :].expand(N_rays, S, -1).reshape(N_rays * S, -1)\n", "    \n", "    rgb, sigma = nerf(x, d)\n", "    rgb = rgb.view(N_rays, S, 3)\n", "    sigma = sigma.view(N_rays, S)\n", "    \n", "    deltas = z_vals[:, 1:] - z_vals[:, :-1]\n", "    deltas = torch.cat([deltas, 1e10 * torch.ones_like(deltas[:, :1])], -1)\n", "    alpha = 1. - torch.exp(-sigma * deltas)\n", "    T = torch.cumprod(\n", "        torch.cat([torch.ones((N_rays, 1), device=alpha.device), 1. - alpha + 1e-10], -1),\n", "        -1\n", "    )[:, :-1]\n", "    weights = alpha * T\n", "    \n", "    rgb_map = (weights[..., None] * rgb).sum(dim=1)\n", "    depth_map = (weights * z_vals).sum(dim=1)\n", "    \n", "    if white_bg:\n", "        acc_map = weights.sum(dim=1, keepdim=True)\n", "        rgb_map = rgb_map + (1. - acc_map)\n", "    \n", "    if return_extras:\n", "        return rgb_map.clamp(0, 1), depth_map, weights, z_vals, sigma\n", "    else:\n", "        return rgb_map.clamp(0, 1), depth_map"]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["## Training Loop"]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": ["import os\n", "import numpy as np\n", "import torch\n", "from tqdm.auto import tqdm\n", "from pathlib import Path\n", "\n", "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n", "\n", "def to_tensor(x):\n", "    if x is None:\n", "        return None\n", "    return torch.from_numpy(x).to(device)\n", "\n", "images = to_tensor(imgs_train).float()\n", "poses = to_tensor(poses_train).float()\n", "depths = to_tensor(depths_train).float() if depths_train is not None else None\n", "\n", "N_imgs, Ht, Wt = images.shape[:3]\n", "psnr_history = []\n", "loss_history = []\n", "\n", "iters = 20000\n", "batch_rays = 1024\n", "lr = 5e-4\n", "N_samples = 64\n", "lambda_soft = 0.01\n", "lambda_hard = 0.005\n", "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n", "\n", "def psnr(mse):\n", "    return -10.0 * torch.log10(mse)\n", "\n", "print('Starting hybrid training...')\n", "pbar = tqdm(range(iters))\n", "\n", "for it in pbar:\n", "    i = torch.randint(0, N_imgs, (1,)).item()\n", "    c2w = poses[i]\n", "    rays_o, rays_d = get_rays(Ht, Wt, focal, c2w)\n", "    target = images[i].view(-1, 3)\n", "    \n", "    idx = torch.randint(0, target.shape[0], (batch_rays,), device=device)\n", "    rays_o_b = rays_o.view(-1, 3)[idx]\n", "    rays_d_b = rays_d.view(-1, 3)[idx]\n", "    target_b = target[idx]\n", "    \n", "    if depths is not None:\n", "        depth_gt_full = depths[i]\n", "        depth_gt_b = depth_gt_full.view(-1)[idx]\n", "        depth_mask_b = (depth_gt_b > 2.0) & (depth_gt_b < 6.0)\n", "    else:\n", "        depth_gt_b = None\n", "        depth_mask_b = None\n", "    \n", "    rgb_pred, depth_pred, weights, z_vals, sigma = render_rays_hybrid(\n", "        model, rays_o_b, rays_d_b,\n", "        near=2.0, far=6.0, N_samples=N_samples,\n", "        depth_gt=depth_gt_b, depth_mask=depth_mask_b,\n", "        eps=0.3, return_extras=True\n", "    )\n", "    \n", "    rgb_loss = F.mse_loss(rgb_pred, target_b)\n", "    \n", "    if depths is not None:\n", "        soft_loss = ((depth_pred - depth_gt_b)**2).mean()\n", "        freespace = free_space_loss(sigma, z_vals, depth_gt_b, depth_mask_b)\n", "        surface = surface_concentration_loss(weights, z_vals, depth_gt_b, depth_mask_b)\n", "        loss = rgb_loss + lambda_soft * soft_loss + lambda_hard * (freespace + surface)\n", "    else:\n", "        soft_loss = torch.tensor(0.0, device=device)\n", "        loss = rgb_loss\n", "    \n", "    optimizer.zero_grad()\n", "    loss.backward()\n", "    optimizer.step()\n", "    \n", "    if (it + 1) % 100 == 0:\n", "        if depths is not None:\n", "            msg = f\"it {it+1} | RGB: {rgb_loss.item():.5f} | Soft: {soft_loss.item():.5f} | PSNR: {psnr(rgb_loss).item():.2f} dB\"\n", "            pbar.set_description(msg)\n", "        else:\n", "            pbar.set_description(f'it {it+1} | loss {loss.item():.5f}')\n", "\n", "save_dir = Path('results/hybrid')\n", "save_dir.mkdir(parents=True, exist_ok=True)\n", "np.save(save_dir / 'psnr_history.npy', np.array(psnr_history))\n", "np.save(save_dir / 'loss_history.npy', np.array(loss_history))\n", "torch.save(model.state_dict(), save_dir / 'model_hybrid.pth')\n", "print(f'Hybrid training complete! Results saved to {save_dir}')"]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}