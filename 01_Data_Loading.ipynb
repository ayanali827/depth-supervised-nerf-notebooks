{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# 01 - Data Loading\n", "\n", "This notebook loads the NeRF Synthetic dataset and prepares it for training."]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": ["# === Cell 2: load dataset (synthetic) ===\n", "import os, json\n", "from pathlib import Path\n", "import numpy as np\n", "import imageio.v2 as imageio\n", "\n", "# For local use, change this path\n", "DATA_DIR = Path(\"data/nerf_synthetic/lego\")  # UPDATE THIS PATH\n", "DEPTH_DIR = Path(\"data/nerf_synthetic/lego\")  # Path to depth .npy files\n", "\n", "def jload(p):\n", "    with open(p, \"r\") as f:\n", "        return json.load(f)\n", "\n", "def load_synthetic_split(split=\"train\", half_res=False):\n", "    meta = jload(DATA_DIR / f\"transforms_{split}.json\")\n", "    \n", "    # Load depth npy if available\n", "    npy_depth_path = DEPTH_DIR / f\"lego_depths_{split}.npy\"\n", "    if npy_depth_path.exists():\n", "        print(f\"Loading depth supervision from {npy_depth_path}\")\n", "        depth_npy = np.load(npy_depth_path)\n", "    else:\n", "        depth_npy = None\n", "    \n", "    imgs, poses, depths = [], [], []\n", "    \n", "    for i, frame in enumerate(meta[\"frames\"]):\n", "        # Load image\n", "        img_path = DATA_DIR / frame[\"file_path\"]\n", "        if not img_path.suffix:\n", "            img_path = img_path.with_suffix(\".png\")\n", "        img = imageio.imread(img_path)\n", "        \n", "        if img.dtype == np.uint16:\n", "            img = (img / 65535.0).astype(np.float32)\n", "        else:\n", "            img = (img / 255.0).astype(np.float32)\n", "        \n", "        if half_res:\n", "            img = img[::2, ::2]\n", "        imgs.append(img)\n", "        \n", "        # Pose\n", "        poses.append(np.array(frame[\"transform_matrix\"], dtype=np.float32))\n", "        \n", "        # Depth from .npy\n", "        if depth_npy is not None:\n", "            d = depth_npy[i]\n", "            if half_res:\n", "                d = d[::2, ::2]\n", "            depths.append(d)\n", "        else:\n", "            depths.append(None)\n", "    \n", "    imgs = np.stack(imgs, 0)\n", "    if imgs.shape[-1] == 4:\n", "        imgs = imgs[..., :3]\n", "    \n", "    poses = np.stack(poses, 0)\n", "    \n", "    if any(d is not None for d in depths):\n", "        depths = np.stack(depths, 0)\n", "    else:\n", "        depths = None\n", "    \n", "    H, W = imgs.shape[1:3]\n", "    camera_angle_x = meta[\"camera_angle_x\"]\n", "    focal = 0.5 * W / np.tan(0.5 * camera_angle_x)\n", "    \n", "    return imgs, poses, depths, H, W, focal\n", "\n", "# Load training and validation splits\n", "imgs_train, poses_train, depths_train, H, W, focal = load_synthetic_split(\"train\", half_res=True)\n", "imgs_val, poses_val, *_ = load_synthetic_split(\"val\", half_res=True)\n", "\n", "print(f\"Train images: {imgs_train.shape}\")\n", "print(f\"Train poses: {poses_train.shape}\")\n", "if depths_train is not None:\n", "    print(f\"Train depths: {depths_train.shape}\")\n", "    print(f\"Depth range: [{depths_train.min():.2f}, {depths_train.max():.2f}]\")\n", "print(f\"H={H}, W={W}, focal={focal:.2f}\")"]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}